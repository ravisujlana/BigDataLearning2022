{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a23473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "conf = SparkConf().setAppName(\"Read File\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a0d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "text = sc.textFile(\"/Users/arjun/Spark/big-data-with-pyspark-and-aws-main/BigDataLearning/Spark/FirstNumberFile.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f172dd",
   "metadata": {},
   "source": [
    "Print by collecting - not to do when data set is large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7c30c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "['1 2 3 4 5', '6 7 8 9 10', '11 12 13 14 15', '16 17 18 19 20']\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n\\n')\n",
    "print(text.collect())\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b0ebbf",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287c0464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', '2', '3', '4', '5'], ['6', '7', '8', '9', '10'], ['11', '12', '13', '14', '15'], ['16', '17', '18', '19', '20']]\n"
     ]
    }
   ],
   "source": [
    "rdd2 = text.map(lambda x:x.split(' '))\n",
    "print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a66568",
   "metadata": {},
   "source": [
    "Append the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c3bbebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = text.map(lambda x:(x + ' Test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20de54a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 2 3 4 5 Test', '6 7 8 9 10 Test', '11 12 13 14 15 Test', '16 17 18 19 20 Test']\n"
     ]
    }
   ],
   "source": [
    "print(rdd3.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb645d5",
   "metadata": {},
   "source": [
    "Next Step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee75a096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']\n"
     ]
    }
   ],
   "source": [
    "flatMap_values = text.flatMap(lambda x:x.split(' '))\n",
    "print(flatMap_values.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "020517c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', '2', '3', '4', '5'], ['6', '7', '8', '9', '10'], ['11', '12', '13', '14', '15'], ['16', '17', '18', '19', '20']]\n"
     ]
    }
   ],
   "source": [
    "def split(input):\n",
    "  localData = input.split(' ')\n",
    "  return localData\n",
    "\n",
    "rddFunc = text.map(split)\n",
    "print(rddFunc.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "340444ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 5, 6, 7, 8], [9, 10, 11, 12, 13], [14, 15, 16, 17, 18], [19, 20, 21, 22, 23]]\n"
     ]
    }
   ],
   "source": [
    "def splitAndAdd(input):\n",
    "  localData = input.split(' ')\n",
    "  l2 = []\n",
    "  for i in localData:\n",
    "      l2.append(int(i) + 3)\n",
    "  return l2\n",
    "\n",
    "rddFuncAdd = text.map(splitAndAdd)\n",
    "print(rddFuncAdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b852a22",
   "metadata": {},
   "source": [
    "Calculate the length of text and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4130c7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 3, 4], [4, 3, 3, 5, 5], [6]]\n"
     ]
    }
   ],
   "source": [
    "stringInput = sc.textFile(\"/Users/arjun/Spark/big-data-with-pyspark-and-aws-main/BigDataLearning/Spark/StringInput.txt\")\n",
    "\n",
    "def countLength(input):\n",
    "  l1 = input.split(' ')\n",
    "  l2 = []\n",
    "  for i in l1:\n",
    "    l2.append(len(i))\n",
    "  return l2\n",
    "\n",
    "rddStringInput = stringInput.map(countLength)\n",
    "\n",
    "print(rddStringInput.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e7c40",
   "metadata": {},
   "source": [
    "Do same using lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "998036ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 3, 4], [4, 3, 3, 5, 5], [6]]\n"
     ]
    }
   ],
   "source": [
    "rddStringLambda = stringInput.map(lambda x:[len(s) for s in x.split(' ')])\n",
    "print(rddStringLambda.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54baf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
